# Steering Large Language Models to Evaluate and Amplify Creativity

**Paper link:** [https://arxiv.org/abs/2412.06060](https://arxiv.org/abs/2412.06060)

## Abstract

Although capable of generating creative text, Large Language Models (LLMs) are poor judges of what constitutes "creativity". In this work, we show that we can leverage this knowledge of how to write creatively in order to better judge what is creative. We take a mechanistic approach that extracts differences in the internal states of an LLM when prompted to respond "boringly" or "creatively" to provide a robust measure of creativity that corresponds strongly with human judgment. We also show these internal state differences can be applied to enhance the creativity of generated text at inference time.